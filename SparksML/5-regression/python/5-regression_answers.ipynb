{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def display(*args, **kargs): pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression\n",
    " \n",
    "This lab covers building regression models using linear regression and decision trees.  Also covered are regression metrics, bootstrapping, and some traditional model evaluation methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read in and prepare the data\n",
    " \n",
    "First, we'll load the data from our parquet file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "baseDir = '/mnt/ml-class/'\n",
    "irisDense = sqlContext.read.parquet(baseDir + 'irisDense.parquet').cache()\n",
    "\n",
    "display(irisDense)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import numpy as np\n",
    "\n",
    "def prepareSubplot(xticks, yticks, figsize=(10.5, 6), hideLabels=False, gridColor='#999999',\n",
    "                gridWidth=1.0, subplots=(1, 1)):\n",
    "    \"\"\"Template for generating the plot layout.\"\"\"\n",
    "    plt.close()\n",
    "    fig, axList = plt.subplots(subplots[0], subplots[1], figsize=figsize, facecolor='white',\n",
    "                               edgecolor='white')\n",
    "    if not isinstance(axList, np.ndarray):\n",
    "        axList = np.array([axList])\n",
    "\n",
    "    for ax in axList.flatten():\n",
    "        ax.axes.tick_params(labelcolor='#999999', labelsize='10')\n",
    "        for axis, ticks in [(ax.get_xaxis(), xticks), (ax.get_yaxis(), yticks)]:\n",
    "            axis.set_ticks_position('none')\n",
    "            axis.set_ticks(ticks)\n",
    "            axis.label.set_color('#999999')\n",
    "            if hideLabels: axis.set_ticklabels([])\n",
    "        ax.grid(color=gridColor, linewidth=gridWidth, linestyle='-')\n",
    "        map(lambda position: ax.spines[position].set_visible(False), ['bottom', 'top', 'left', 'right'])\n",
    "\n",
    "    if axList.size == 1:\n",
    "        axList = axList[0]  # Just return a single axes object for a regular plot\n",
    "    return fig, axList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = irisDense.collect()\n",
    "features, labels = zip(*data)\n",
    "x1, y1, x2, y2 = zip(*features)\n",
    "\n",
    "colorMap = 'Set1'  # was 'Set2', 'Set1', 'Dark2', 'winter'\n",
    "\n",
    "fig, axList = prepareSubplot(np.arange(-1, 1.1, .2), np.arange(-1, 1.1, .2), figsize=(11., 5.), subplots=(1, 2))\n",
    "ax0, ax1 = axList\n",
    "\n",
    "ax0.scatter(x1, y1, s=14**2, c=labels, edgecolors='#444444', alpha=0.80, cmap=colorMap)\n",
    "ax0.set_xlabel('Sepal Length'), ax0.set_ylabel('Sepal Width')\n",
    "\n",
    "ax1.scatter(x2, y2, s=14**2, c=labels, edgecolors='#444444', alpha=0.80, cmap=colorMap)\n",
    "ax1.set_xlabel('Petal Length'), ax1.set_ylabel('Petal Width')\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "display(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare the data so that we have the sepal width as our target and a dense vector containing sepal length as our features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf, lit\n",
    "from pyspark.sql.types import DoubleType\n",
    "from pyspark.mllib.linalg import VectorUDT, Vectors\n",
    "\n",
    "getElement = udf(lambda v, i: float(v[i]), DoubleType())\n",
    "getElementAsVector = udf(lambda v, i: Vectors.dense([v[i]]), VectorUDT())\n",
    "\n",
    "irisSepal = irisDense.select(getElement('features', lit(1)).alias('sepalWidth'),\n",
    "                             getElementAsVector('features', lit(0)).alias('features'))\n",
    "irisSepal.cache()\n",
    "\n",
    "display(irisSepal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build a linear regression model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we'll sample from our dataset to obtain a [bootstrap sample](https://en.wikipedia.org/wiki/Bootstrapping_%28statistics%29) of our data.\n",
    " \n",
    "When using a `DataFrame` we can call `.sample` to return a random sample with or without replacement.  `sample` takes in a boolean for whether to sample with replacement and a fraction for what percentage of the dataset to sample.  Note that if replacement is true we can sample more than 100% of the data.  For example, to choose approximately twice as much data as the original dataset we can set fraction equal to 2.0.\n",
    " \n",
    "An explanation of `sample` can be found under `DataFrame` in both the [Python](https://spark.apache.org/docs/latest/api/python/pyspark.sql.html#pyspark.sql.DataFrame.sample) and [Scala](http://spark.apache.org/docs/latest/api/scala/#org.apache.spark.sql.DataFrame) APIs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "help(irisSepal.sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "irisSepalSample = irisSepal.sample(True, 1.0, 1)\n",
    "display(irisSepalSample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's create our linear regression object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import LinearRegression\n",
    "\n",
    "lr = (LinearRegression()\n",
    "      .setLabelCol('sepalWidth')\n",
    "      .setMaxIter(1000))\n",
    "print lr.explainParams()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll create a `Pipeline` that only contains one stage for the linear regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.pipeline import Pipeline\n",
    "pipeline = Pipeline().setStages([lr])\n",
    "\n",
    "pipelineModel = pipeline.fit(irisSepalSample)\n",
    "sepalPredictions = pipelineModel.transform(irisSepalSample)\n",
    "\n",
    "display(sepalPredictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What does our resulting model look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lrModel = pipelineModel.stages[-1]\n",
    "print type(lrModel)\n",
    "\n",
    "print '\\n', lrModel.intercept, lrModel.weights\n",
    "\n",
    "print '\\nsepalWidth = {0:.3f} + ({1:.3f} * sepalLength)'.format(lrModel.intercept, lrModel.weights[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visualize this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "colorMap = 'Set1'  # was 'Set2', 'Set1', 'Dark2', 'winter'\n",
    "\n",
    "def generatePlotDataAndModel(lrModels, linestyle='--', alpha=.80, x=x1, y=y1,\n",
    "                             xlab='Sepal Length', ylab='Sepal Width'):\n",
    "    fig, ax = prepareSubplot(np.arange(-1, 1.1, .2), np.arange(-1, 1.1, .2), figsize=(7., 5.))\n",
    "\n",
    "    ax.set_xlim((-1.1, 1.1)), ax.set_ylim((-1.1, 1.1))\n",
    "    ax.scatter(x, y, s=14**2, c='red', edgecolors='#444444', alpha=0.60, cmap=colorMap)\n",
    "    ax.set_xlabel(xlab), ax.set_ylabel(ylab)\n",
    "\n",
    "    for lrModel in lrModels:\n",
    "        intercept = lrModel.intercept\n",
    "        slope = lrModel.weights[0]\n",
    "        lineStart = (-2.0, intercept + (slope * -2.0))\n",
    "        lineEnd = (2.0, intercept + (slope * 2.0))\n",
    "        line = [lineStart, lineEnd]\n",
    "        xs, ys = zip(*line)\n",
    "\n",
    "        ax.plot(xs, ys, c='orange', linestyle=linestyle, linewidth=3.0, alpha=alpha)\n",
    "\n",
    "    fig.tight_layout()\n",
    "\n",
    "    return fig\n",
    "\n",
    "fig = generatePlotDataAndModel([lrModel])\n",
    "display(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Boostrap sampling 100 models\n",
    " \n",
    "In order to reason about how stable our models are and whether or not the coefficients are significantly different from zero, we'll draw 100 samples with replacement and generate a linear model for each of those samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def generateModels(df, pipeline, numModels=100):\n",
    "    models = []\n",
    "\n",
    "    for i in range(numModels):\n",
    "        sample = df.sample(True, 1.0, i)\n",
    "        pipelineModel = pipeline.fit(sample)\n",
    "        models.append(pipelineModel.stages[-1])\n",
    "\n",
    "    return models\n",
    "\n",
    "sepalModels = generateModels(irisSepal, pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll convert our models to a `DataFrame` so we can analyze the different values we obtained for intercept and weight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import Row\n",
    "sepalModelsRow = map(lambda m: Row(intercept=float(m.intercept), weight=float(m.weights[0])), sepalModels)\n",
    "sepalModelResults = sqlContext.createDataFrame(sepalModelsRow)\n",
    "display(sepalModelResults)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can use `describe` to see the count, mean, and standard deviation of our intercept and weight.  Based on these results it is pretty clear that there isn't a significant relationship between sepal length and sepal width."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "display(sepalModelResults.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visualize the 100 models we just generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig = generatePlotDataAndModel(sepalModels, linestyle='-', alpha=.05)\n",
    "display(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll visualize the probability distribution function (PDF) for the weight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "w = sorted(map(lambda m: m.weights[0], sepalModels))\n",
    "w2_5= (w[1] + w[2]) / 2.0\n",
    "w97_5 = (w[96] + w[97]) / 2.0\n",
    "wDiff = w97_5 - w2_5\n",
    "\n",
    "density = stats.kde.gaussian_kde(w)\n",
    "x = np.arange(-1.0, 1.0, .01)\n",
    "xDensity = density(x)\n",
    "\n",
    "dMin, dMax = xDensity.min(), xDensity.max()\n",
    "\n",
    "fig, ax = prepareSubplot(np.arange(-.6, .7, .1), np.arange(-1, 10.1, 1.), figsize=(7., 5.))\n",
    "\n",
    "circle1=plt.Rectangle((w2_5, 0), wDiff, 100, color='#444444', alpha=.10, linewidth=2)\n",
    "ax.add_artist(circle1)\n",
    "\n",
    "ax.plot(x, xDensity, color='red', linewidth=4.0, alpha=.70)\n",
    "ax.plot([0, 0], [0, 100], color='orange', linestyle='--', linewidth=5.0)\n",
    "\n",
    "ax.set_xlim((-.5, .4)), ax.set_ylim((-.3, 7.6))\n",
    "ax.set_xlabel('weight'), ax.set_ylabel('density')\n",
    "display(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can also visualize the cumulative distribution function (CDF) for the weight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def prepareCDFPlot(w):\n",
    "    wMax, wMin = max(w), min(w)\n",
    "    diff = wMax - wMin\n",
    "    diffInc = round(diff / 10.0, 2)\n",
    "\n",
    "    fig, ax = prepareSubplot(np.arange(round(wMin, 2), wMax + diffInc, diffInc), np.arange(0, 101, 10),\n",
    "                             figsize=(7., 5.))\n",
    "\n",
    "    x = list(range(len(w)))\n",
    "    ax.plot(w, x, color='red', linewidth=4.0, alpha=.70)\n",
    "\n",
    "    circle1=plt.Rectangle((wMin, 2.5), diff, 95.0, color='#444444', alpha=.10, linewidth=2)\n",
    "    ax.add_artist(circle1)\n",
    "    ax.plot([0, 0], [0, 100], color='orange', linestyle='--', linewidth=5.0)\n",
    "\n",
    "    ax.set_xlim(wMin, wMax), ax.set_ylim(0, 100)\n",
    "    ax.set_xlabel('weight'), ax.set_ylabel('percentile')\n",
    "    return fig\n",
    "\n",
    "fig = prepareCDFPlot(w)\n",
    "display(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Petal width vs petal length\n",
    " \n",
    "We saw that there wasn't a significant relationship between sepal width and sepal length.  Let's repeat the analysis for the petal attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "irisPetal = irisDense.select(getElement('features', lit(3)).alias('petalWidth'),\n",
    "                             getElementAsVector('features', lit(2)).alias('features'))\n",
    "irisPetal.cache()\n",
    "display(irisPetal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the linear regression estimator and pipeline estimator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lrPetal = (LinearRegression()\n",
    "           .setLabelCol('petalWidth'))\n",
    "\n",
    "petalPipeline = Pipeline().setStages([lrPetal])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "petalModels = generateModels(irisPetal, petalPipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll repeat the conversion of the model data to a `DataFrame` and then view the statistics on the `DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "petalModelsRow = map(lambda m: Row(intercept=float(m.intercept), weight=float(m.weights[0])), petalModels)\n",
    "petalModelResults = sqlContext.createDataFrame(petalModelsRow)\n",
    "display(petalModelResults)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From these results, we can clearly see that this weight is significantly different from zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "display(petalModelResults.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visualize the 100 models we just generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig = generatePlotDataAndModel(petalModels, linestyle='-', alpha=.05, x=x2, y=y2,\n",
    "                               xlab='Petal Length', ylab='Petal Width')\n",
    "display(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll visualize the probability distribution function (PDF) for the weight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "w = sorted(map(lambda m: m.weights[0], petalModels))\n",
    "\n",
    "density = stats.kde.gaussian_kde(w)\n",
    "x = np.arange(.8, 1.2, .01)\n",
    "xDensity = density(x)\n",
    "\n",
    "dMin, dMax = xDensity.min(), xDensity.max()\n",
    "\n",
    "w2_5= (w[1] + w[2]) / 2.0\n",
    "w97_5 = (w[96] + w[97]) / 2.0\n",
    "wDiff = w97_5 - w2_5\n",
    "\n",
    "fig, ax = prepareSubplot(np.arange(.9, 1.2, .05), np.arange(-1, 25, 3.), figsize=(7., 5.))\n",
    "\n",
    "circle1=plt.Rectangle((w2_5, 0), wDiff, 100, color='#444444', alpha=.10, linewidth=2)\n",
    "ax.add_artist(circle1)\n",
    "\n",
    "ax.plot(x, xDensity, color='red', linewidth=4.0, alpha=.70)\n",
    "ax.plot([0, 0], [0, 100], color='orange', linestyle='--', linewidth=5.0)\n",
    "\n",
    "ax.set_xlim((.9, 1.15)), ax.set_ylim((-.3, 25))\n",
    "ax.set_xlabel('weight'), ax.set_ylabel('density')\n",
    "display(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can also visualize the cumulative distribution function (CDF) for the weight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig = prepareCDFPlot(w)\n",
    "display(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### View and evaluate predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start, we'll generate the predictions by using the first model in `petalModels`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "petalPredictions = petalModels[0].transform(irisPetal)\n",
    "display(petalPredictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll evaluate the model using the `RegressionEvaluator`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "regEval = RegressionEvaluator().setLabelCol('petalWidth')\n",
    "\n",
    "print regEval.explainParams()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The default value for `RegressionEvaluator` is root mean square error (RMSE).  Let's view that first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print regEval.evaluate(petalPredictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`RegressionEvaluator` also supports mean square error (MSE), \\\\( r^2 \\\\), and mean absolute error (MAE).  We'll view the \\\\( r^2 \\\\) metric next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print regEval.evaluate(petalPredictions, {regEval.metricName: 'r2'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's evaluate our model on the sepal data as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sepalPredictions = sepalModels[0].transform(irisSepal)\n",
    "print regEval.evaluate(sepalPredictions,\n",
    "                       {regEval.metricName: 'r2', regEval.labelCol: 'sepalWidth'})\n",
    "print regEval.evaluate(sepalPredictions,\n",
    "                       {regEval.metricName: 'rmse', regEval.labelCol: 'sepalWidth'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regression with decision trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import DecisionTreeRegressor\n",
    "\n",
    "dtr = DecisionTreeRegressor().setLabelCol('petalWidth')\n",
    "print dtr.explainParams()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dtrModel = dtr.fit(irisPetal)\n",
    "dtrPredictions = dtrModel.transform(irisPetal)\n",
    "print regEval.evaluate(dtrPredictions, {regEval.metricName: 'r2'})\n",
    "print regEval.evaluate(dtrPredictions, {regEval.metricName: 'rmse'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also build a gradient boosted tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import GBTRegressor\n",
    "gbt = GBTRegressor().setLabelCol('petalWidth')\n",
    "print gbt.explainParams()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gbtModel = gbt.fit(irisPetal)\n",
    "gbtPredictions = gbtModel.transform(irisPetal)\n",
    "print regEval.evaluate(gbtPredictions, {regEval.metricName: 'r2'})\n",
    "print regEval.evaluate(gbtPredictions, {regEval.metricName: 'rmse'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should really test our gradient boosted tree out-of-sample as it is easy to overfit with a GBT model."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 0
}
