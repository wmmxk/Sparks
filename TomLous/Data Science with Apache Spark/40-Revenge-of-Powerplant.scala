{"version":"NotebookV1","origId":503877321548806,"name":"40-Revenge-of-Powerplant","language":"scala","commands":[{"version":"CommandV1","origId":503877321548808,"guid":"f06af546-59f5-4e25-bc2f-15331bbc349f","subtype":"command","commandType":"auto","position":1.0,"command":"%md Because so much of the power plant output information is contained in the temperature variable, we did fairly well with the simple one-dimensional regression. But we do have more information available, which might help us build a better model. \n\nAnd of course we want to see how to do more interesting modeling with Spark -- so let's try it again\n\nThis time, we'll use all four predictors, and more importantly, we'll look at more Spark features that help us manage these modeling tasks.","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0.0,"submitTime":0.0,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"b143b3e0-ab68-4608-8a9c-f364a0104738"},{"version":"CommandV1","origId":503877321548809,"guid":"8c53df2f-ed03-4e77-b4c3-abd83d546e5c","subtype":"command","commandType":"auto","position":2.0,"command":"val data = spark.read\n  .option(\"delimiter\", \"\\\\t\")\n  .option(\"header\", true)\n  .option(\"inferSchema\", true)\n  .csv(\"dbfs:/databricks-datasets/power-plant/data/\")\n\ndata.show(5)","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0.0,"submitTime":0.0,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"6109f7f9-65e4-4356-b7de-c4ea7e4b64fa"},{"version":"CommandV1","origId":503877321548810,"guid":"62ea9fb3-0a0e-4309-b5d4-ba62ea7765c0","subtype":"command","commandType":"auto","position":3.0,"command":"%md **Schema Definition**\n\nOur schema definition from UCI appears below:\n\n- AT = Atmospheric Temperature in C\n- V = Exhaust Vaccum Speed\n- AP = Atmospheric Pressure\n- RH = Relative Humidity\n- PE = Power Output\n\nPE is our label or target. This is the value we are trying to predict given the measurements.\n\n*Reference [UCI Machine Learning Repository Combined Cycle Power Plant Data Set](https://archive.ics.uci.edu/ml/datasets/Combined+Cycle+Power+Plant)*","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0.0,"submitTime":0.0,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"639e308b-9ac3-4338-903b-df6e0ce27ce2"},{"version":"CommandV1","origId":503877321548811,"guid":"7c1c315e-4446-4fcb-a4f3-93a5c9549d2e","subtype":"command","commandType":"auto","position":4.0,"command":"%md Let's use Databricks to get a quick look at the relationships of each variable to our target","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0.0,"submitTime":0.0,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"f11c7ab9-8b6a-4890-9c13-9b6c39a673ef"},{"version":"CommandV1","origId":503877321548812,"guid":"6137a57c-2c74-4d8e-b308-4104719461ff","subtype":"command","commandType":"auto","position":5.0,"command":"display(data)","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0.0,"submitTime":0.0,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"dda56781-a903-4543-a323-b8d32f613254"},{"version":"CommandV1","origId":503877321548813,"guid":"aab5a213-c604-43eb-84cf-394e8f99595d","subtype":"command","commandType":"auto","position":6.0,"command":"%md Here we can look see...\n\n* How each predictor relates to our target (PE)\n\nand equally important\n\n* How the predictors relate to each other -- in particular, it's valuable to know if we have *highly correlated predictors* as these partly redundant dimensions can affect our modeling in several ways\n\nConsider AT vs. AP ... ","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0.0,"submitTime":0.0,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"72c59c19-9c14-401f-a692-29f82349890d"},{"version":"CommandV1","origId":503877321548814,"guid":"5ee7dc69-2ff0-41ea-957f-5dac7094fa8b","subtype":"command","commandType":"auto","position":7.0,"command":"%md Ok, let's get these records into a proper vector form using an offical API helper tool called a Transformer\n\nInternally, it's not magic compared to our UDF -- it's just an organized, standardized way to expose logic in a reusable way that covers a variety of cases.","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0.0,"submitTime":0.0,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"e9456953-1da4-4837-acab-872b91e33ea0"},{"version":"CommandV1","origId":503877321548815,"guid":"465d21b9-9e47-4aeb-82ce-0aeeb0ec0e80","subtype":"command","commandType":"auto","position":8.0,"command":"import org.apache.spark.ml.feature.VectorAssembler\n\nval vecAssembler = new VectorAssembler()\n\nvecAssembler.setInputCols(Array(\"AT\", \"V\", \"AP\", \"RH\"))\n\nvecAssembler.setOutputCol(\"features\")","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0.0,"submitTime":0.0,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"bb16d0b0-e210-4dab-b40c-19b1a628440a"},{"version":"CommandV1","origId":503877321548816,"guid":"f24407ac-12c8-4e9e-b76b-4e5a9fd0b5af","subtype":"command","commandType":"auto","position":9.0,"command":"%md How do we use it? Transformers' key API method is `.transform(aDataFrame)`","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0.0,"submitTime":0.0,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"e96a1f72-078c-4517-b0d1-5415d9a004e7"},{"version":"CommandV1","origId":503877321548817,"guid":"5b07460e-294b-4948-99d9-74def9fc2890","subtype":"command","commandType":"auto","position":10.0,"command":"display(vecAssembler.transform(data))","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0.0,"submitTime":0.0,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"9c8f5f61-1ebb-4b49-b124-eeb0a9972e24"},{"version":"CommandV1","origId":503877321548818,"guid":"db76fd35-a29f-4a7b-b630-36c87127c070","subtype":"command","commandType":"auto","position":11.0,"command":"var Array(split20, split80) = data.randomSplit(Array(0.20, 0.80), 42)\nval testSet = split20.cache()\nval trainingSet = split80.cache()","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0.0,"submitTime":0.0,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"7fc8b8fc-8652-44a0-8298-819089d4629f"},{"version":"CommandV1","origId":503877321548819,"guid":"f2bcfec9-ed67-4dff-b6ed-9df7eb28530f","subtype":"command","commandType":"auto","position":12.0,"command":"import org.apache.spark.ml.regression.LinearRegression\nimport org.apache.spark.ml.regression.LinearRegressionModel\nimport org.apache.spark.ml.Pipeline\n\nval lr = new LinearRegression()","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0.0,"submitTime":0.0,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"848dbcd9-95d6-4330-b642-cf05f20649e5"},{"version":"CommandV1","origId":503877321548820,"guid":"f1e9714a-bf8d-4937-9ba1-6758fb0b31d2","subtype":"command","commandType":"auto","position":13.0,"command":"%md We use `explainParams` to dump the parameters we can use -- we'll start with defaults, see how it works out, and then manually try a couple of variants\n\n(Later today we'll see how to get Spark to tune parameters for us)","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0.0,"submitTime":0.0,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"b3e90470-e898-4195-9051-bd247f325858"},{"version":"CommandV1","origId":503877321548821,"guid":"2f855d82-18c1-41db-a458-d64c992457e4","subtype":"command","commandType":"auto","position":14.0,"command":"lr.explainParams()","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0.0,"submitTime":0.0,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"d7d1030e-3bff-4d3a-8aa7-86595092493f"},{"version":"CommandV1","origId":503877321548822,"guid":"c894d350-d4e3-441b-964c-fc8ee58f3c64","subtype":"command","commandType":"auto","position":15.0,"command":"%md Let's look at one of these \"parameters\" \n\nML API \"Params\" have their own special (though simple) patterns in Spark -- they're not just class members.\n\nWhy? Because we want them to be usable not just by us human programmers, but by other components through reflection, and via straightforward bindings that are seamlessly compatible with other languages and their types. Specifically, Python.","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0.0,"submitTime":0.0,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"e3ac285f-aea2-43d3-b70d-fb29f7b2ce28"},{"version":"CommandV1","origId":503877321548823,"guid":"189280c2-b6f5-4e13-9993-75095bb21000","subtype":"command","commandType":"auto","position":16.0,"command":"lr.labelCol","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0.0,"submitTime":0.0,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"bcf52d15-8e09-4831-97d5-a3f3392eab6e"},{"version":"CommandV1","origId":503877321548824,"guid":"0863cd40-a044-4cf9-8cc0-1222eea1f7a7","subtype":"command","commandType":"auto","position":17.0,"command":"lr.setLabelCol(\"PE\") // why didn't we have to do this earlier? because the default for the \"label\" column in most classes is \"label\"\n// since we had renamed the PE column to \"label\" in the earlier example, we could get away with the default\n\n// Defaults are not just for laziness! They make code more reusable and more understandable by others ... so take advantage when you can","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0.0,"submitTime":0.0,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"2e5a8b06-f544-4e3f-b0e3-81577bd75d0e"},{"version":"CommandV1","origId":503877321548825,"guid":"17323e12-a0d8-48c1-80a1-8ff40ea861d7","subtype":"command","commandType":"auto","position":18.0,"command":"%md Now we're ready to fit our Linear Regression to our data ... or are we?","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0.0,"submitTime":0.0,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"7d7bfd9e-813d-4bb8-8183-72cd331b1676"},{"version":"CommandV1","origId":503877321548826,"guid":"131d44b2-4e5d-4259-8065-764bb6b0d643","subtype":"command","commandType":"auto","position":19.0,"command":"try {\n  lr.fit(trainingSet)\n} catch {\n  case e:Exception => println(e)\n}","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0.0,"submitTime":0.0,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"d284de8f-c083-4e1d-8d0b-0a805422bd6b"},{"version":"CommandV1","origId":503877321548827,"guid":"3f755978-be41-43de-9899-acc667778134","subtype":"command","commandType":"auto","position":20.0,"command":"%md What happened? At first it might look like we just got a column name wrong -- and that's a good instinct, as that is a simple error that often comes up -- but in fact, the problem is we need to run our VectorAssembler over the data to reshape it (and that produces te \"features\" column)","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0.0,"submitTime":0.0,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"190f442a-5a57-45b6-b0ea-6f07357103ac"},{"version":"CommandV1","origId":503877321548828,"guid":"f54fbbda-6711-4dbf-a4e4-56acc7bddc32","subtype":"command","commandType":"auto","position":21.0,"command":"val linearModel = lr.fit( vecAssembler.transform(trainingSet) )","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0.0,"submitTime":0.0,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"ebf79082-9700-4903-ac0c-438547b35bd0"},{"version":"CommandV1","origId":503877321548829,"guid":"c929f342-4442-46ed-bc69-961286de9c79","subtype":"command","commandType":"auto","position":22.0,"command":"%md Success! But before we jump into testing and evaulating our model, notice the pattern of composition above.\n\nIt's not too bad with just one Transformer, but if we had multiple Transformers, there would be a lot of composition.\n\nTo make things more tricky, if we used any Estimators to preprocess our features -- even simple things like StringIndexer -- we would need to include two steps for each of those (fit and transform).\n\nBecause the API is consistent, the pattern is totally mechanical to apply, but leads to a lot of code. Also, it's hard re-use the steps in the process without applying them to the actual data.\n\nSimplifying lots of consistent, mechanical calls? Encapsulating a process? Sounds like something that can be fixed with code!\n\nThat is the motivation for the Pipeline class, a wrapper around a series of Transformers and Estimators. The Pipeline code knows which APIs to call (transform vs. fit + transform) and it encapsulates the computation without requiring the data itself. (This is sometimes referred to as point-free style.)","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0.0,"submitTime":0.0,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"a488c9ce-fc20-4582-834e-14eb4eefcb3d"},{"version":"CommandV1","origId":503877321548830,"guid":"ad2fcc83-6765-4009-a756-5a4fe84a381c","subtype":"command","commandType":"auto","position":23.0,"command":"// We will use the new spark.ml pipeline API. If you have worked with scikit-learn this will be very familiar.\nval lrPipeline = new Pipeline()\n\nlrPipeline.setStages(Array(vecAssembler, lr))\n\n// Pipelines are themselves Estimators -- so to use them we call fit:\n\nval lrModel = lrPipeline.fit(trainingSet)","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0.0,"submitTime":0.0,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"bc0c2730-5e3f-4d72-946e-0aca802827da"},{"version":"CommandV1","origId":503877321548831,"guid":"8db7cb68-798e-4d58-9b02-20c758e2ab58","subtype":"command","commandType":"auto","position":24.0,"command":"%md \nSince Linear Regression is Simply a Line of best fit over the data that minimizes the square of the error, given multiple input dimensions we can express each predictor as a line function of the form:\n\n\\\\[ y = a + b x_1 + b x_2 + b x_i ... \\\\]\n\nwhere a is the intercept and b are coefficients.\n\nTo express the coefficients of that line we can retrieve the Estimator stage from the PipelineModel and express the weights and the intercept for the function.","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0.0,"submitTime":0.0,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"e5ed30fa-87d7-4f42-ae52-29e4f7badfae"},{"version":"CommandV1","origId":503877321548832,"guid":"82606155-c29b-461d-895c-368bbc0362b7","subtype":"command","commandType":"auto","position":25.0,"command":"// The intercept is as follows:\nval intercept = lrModel.stages(1).asInstanceOf[LinearRegressionModel].intercept","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0.0,"submitTime":0.0,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"ab878b72-7725-4aca-88e2-8adafa710755"},{"version":"CommandV1","origId":503877321548833,"guid":"3d4d20a3-cea1-4af1-85a2-372dc75099e8","subtype":"command","commandType":"auto","position":26.0,"command":"// The coefficents (i.e. weights) are as follows:\n\nval weights = lrModel.stages(1).asInstanceOf[LinearRegressionModel].coefficients\n\nvecAssembler.getInputCols","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0.0,"submitTime":0.0,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"915a61d1-68e0-40ff-ad09-ac6f163ae110"},{"version":"CommandV1","origId":503877321548834,"guid":"f4b6f01f-a77b-4778-8ca1-14a813438e29","subtype":"command","commandType":"auto","position":27.0,"command":"%md Most Spark models allow visibility into the calculated parameters -- this can tell us about the significance of the parameters, and can also be used to reimplement a trained model in another system. That's one deployment strategy we'll revisit toward the end of the day.","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0.0,"submitTime":0.0,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"e5fb0eb4-efd7-4c05-bfa7-039c6796f75c"},{"version":"CommandV1","origId":503877321548835,"guid":"50540f69-4f8e-4977-89ec-0bd15b863b0d","subtype":"command","commandType":"auto","position":28.0,"command":"%md Scroll back up and take a look at the plot of pressure vs. output and humidity vs. output\n\nIt looks like pressure (\"AP\") should be bigger factor in a linear model of output ... but the coefficient for humidity (\"RH\") is 2.5x as large.\n\nWhat's going on here?","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0.0,"submitTime":0.0,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"95eb04ee-2e21-4831-8a7c-0e6da3cf4be3"},{"version":"CommandV1","origId":503877321548836,"guid":"f0ad0d75-fa9f-458e-9595-9fa3da8fa16e","subtype":"command","commandType":"auto","position":29.0,"command":"display(data.describe())","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0.0,"submitTime":0.0,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"75406a5a-9b2e-405c-a25c-dd37d8d1e9a0"},{"version":"CommandV1","origId":503877321548837,"guid":"dcde5448-dcec-4ad1-aa2e-7820294efce5","subtype":"command","commandType":"auto","position":30.0,"command":"%md The variance for RH is about 3x as large as that for AP ... if we wanted to get everything on the same scale, we could scale (sd=1) and center (mean=0) the data before processing it using another feature processing helper.\n\nFor now, let see how well the model does with the 4 predictors, and see how we can do a little bit of manual tuning on the algorithm.","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0.0,"submitTime":0.0,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"c96f59a8-d093-4648-984c-9fba6404ac15"},{"version":"CommandV1","origId":503877321548838,"guid":"d9f7c6a8-6900-4281-bd07-289ce6c8a5b4","subtype":"command","commandType":"auto","position":31.0,"command":"val predictionsAndLabels = lrModel.transform(testSet)\n\ndisplay(predictionsAndLabels.select('PE, 'prediction))","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0.0,"submitTime":0.0,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"ccd5edbd-3490-4538-8478-ba1d1b56d09b"},{"version":"CommandV1","origId":503877321548839,"guid":"1c9c78bc-4543-4aff-99b0-c3529d6f4d46","subtype":"command","commandType":"auto","position":32.0,"command":"%md Now that we have real predictions we can use an evaluation metric such as Root Mean Squared Error to validate our regression model. The lower the Root Mean Squared Error, the better our model.\n\nIn the first example, we used a RegressionEvaluator to get a metric. RegressionEvaluator (and other \\*Evaluator classes) are the official \"modern\" way to get statistics on our models, and they are also designed to interface with other Spark classes (which we'll see later) to perform hyperparameter grid search, or find parameters that perform best.\n\nHowever, occasionally we might want to use some older classes from the mllib API -- in this case, because we can quickly get several stats out at once. Other reasons might be using functionality like SVD that hasn't been ported to SparkML yet.\n\nHere's how we can take a DataFrame and produce the RDD of pairs of Doubles that the older mllib RegressionMetrics class uses:","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0.0,"submitTime":0.0,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"87fcb7b2-81d1-4d77-ba22-81d8d4896d08"},{"version":"CommandV1","origId":503877321548840,"guid":"9c4aaf51-5128-405b-97ec-29fe358ecb19","subtype":"command","commandType":"auto","position":33.0,"command":"import org.apache.spark.mllib.evaluation.RegressionMetrics \nimport org.apache.spark.sql.DataFrame\n\ndef printStats(df:DataFrame, predictionColName:String, labelColName:String) = {\n  val justPredictionAndLabelDF = df.select(predictionColName, labelColName)\n  val rddOfPairs = justPredictionAndLabelDF.rdd.map(r => (r(0).asInstanceOf[Double], r(1).asInstanceOf[Double]))\n  val metrics = new RegressionMetrics(rddOfPairs)\n  \n  val rmse = metrics.rootMeanSquaredError\n  val explainedVariance = metrics.explainedVariance\n  val r2 = metrics.r2\n\n  println (f\"Root Mean Squared Error: $rmse\")\n  println (f\"Explained Variance: $explainedVariance\")  \n  println (f\"R2: $r2\")\n}","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0.0,"submitTime":0.0,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"001c7768-d1e3-46d0-8797-4e404f8ef2c0"},{"version":"CommandV1","origId":503877321548841,"guid":"0161b6d5-1488-42d4-b10b-7fa9ea4f2a84","subtype":"command","commandType":"auto","position":34.0,"command":"printStats(predictionsAndLabels, \"prediction\", \"PE\")","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0.0,"submitTime":0.0,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"7caeb067-03ed-4d6d-986b-bed1e76a5849"},{"version":"CommandV1","origId":503877321548842,"guid":"6dc57248-6fc2-486c-89c7-d21cf2a1b7f5","subtype":"command","commandType":"auto","position":35.0,"command":"%md __Manual Tuning__\n\nNow that we have a model with all of the data let's try to make a better model by tuning over several parameters to see if we can get better results.\n\n*Note: to keep the code super short and simple in the following cells, we're mutating the (stateful) LinearRegression object. So take care to run the following cells in order. If you don't, both Spark and your code will still work, but you might not realize what the current parameters are. Unlike, e.g., many R algorithms, this class will not print out the config that was used (though you can interrogate it using getters)*","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0.0,"submitTime":0.0,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"338f2010-85db-43b8-b7d2-c262b50c93a8"},{"version":"CommandV1","origId":503877321548843,"guid":"2b2c23fa-184e-4181-afcd-abdd0fbd4ade","subtype":"command","commandType":"auto","position":36.0,"command":"lr.setRegParam(0.02) // L2 by default\n\nval predictionsAndLabels = lrPipeline.fit(trainingSet).transform(testSet)\nprintStats(predictionsAndLabels, \"prediction\", \"PE\")","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0.0,"submitTime":0.0,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"18f0261d-ad27-4449-99f5-b7bab476dd12"},{"version":"CommandV1","origId":503877321548844,"guid":"a150f116-6f6e-442e-88e1-eeef7bcc0243","subtype":"command","commandType":"auto","position":37.0,"command":"lr.setRegParam(0.02)\n\nval predictionsAndLabels = lrPipeline.fit(trainingSet).transform(testSet)\nprintStats(predictionsAndLabels, \"prediction\", \"PE\")","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0.0,"submitTime":0.0,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"94bb921c-4bb4-4bde-8f5a-9b71a48451a7"},{"version":"CommandV1","origId":503877321548845,"guid":"24714f28-a9a3-43e6-8681-9b984cd9c6f4","subtype":"command","commandType":"auto","position":38.0,"command":"lr.setElasticNetParam(0.1) // 0 == L2 ... 1 == L1\nlr.setRegParam(0.04)\n\nval predictionsAndLabels = lrPipeline.fit(trainingSet).transform(testSet)\nprintStats(predictionsAndLabels, \"prediction\", \"PE\")","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0.0,"submitTime":0.0,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"a03c5843-3457-4255-a4b0-3d30c70bbcc2"},{"version":"CommandV1","origId":503877321548846,"guid":"b81ff055-62a3-4ab1-9b01-eb29b67ef088","subtype":"command","commandType":"auto","position":39.0,"command":"%md So these tuning options are not changing the results very much. But there are lots of params we could change ... and lots of possible values.\n\nOnce again, this seems like something that could benefit from automation!\n\nAnd, in fact, one of the guiding principles behind this API (for example, the way parameters are handled) is enabling this automation. A little bit later, we'll see how SparkML provides a simple (just 2 classes that we haven't seen yet) framework for automatically testing out combinations of parameters and choosing the best ones.","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0.0,"submitTime":0.0,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"0104a3d6-9d38-4be5-abd7-71d51361bfaf"},{"version":"CommandV1","origId":503877321548847,"guid":"974b531d-c0cf-4ff4-ab49-7534095ed610","subtype":"command","commandType":"auto","position":40.0,"command":"%md *(advanced/extra credit: Linear Regression -- and a number of other Spark algorithm implementations -- supports multiple \"solvers,\" i.e., multiple mathematical approaches to determining the solution ... in the case of Linear Regression, there is support for Weighted Least Squares, L-BFGS, and OWL-QN ... familiarize yourself with these approaches and take a look at the Spark source code to see how the selection of solver is made. Users can also override the choice of solver with an API call.)*","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0.0,"submitTime":0.0,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"15aae760-ebf4-4e23-acc5-2dce34e62041"},{"version":"CommandV1","origId":503877321548848,"guid":"2cc9c1d3-3044-42b8-8005-13124934fa1b","subtype":"command","commandType":"auto","position":41.0,"command":"","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0.0,"submitTime":0.0,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"17a33983-b34d-4d10-b8c5-9c9541ad3e10"}],"dashboards":[],"guid":"e78434c8-187d-4bf6-94f0-7dfaf174c608","globalVars":{},"iPythonMetadata":null,"inputWidgets":{}}